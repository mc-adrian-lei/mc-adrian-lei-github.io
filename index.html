<!DOCTYPE html>
<html lang="en">
<head>
  <!--
    Developer Notes — 2025-10-16
    Summary of changes for codec/code reviewers:
    • Replaced generic “Mind/Body/Soul Aspect #” placeholders with a canonical list of 32 faculties of consciousness.
      – The constant FACULTIES[] (JS) now defines the clock order and feeds every aspect’s display name.
      – makeAspectSet(model) now sets `name: FACULTIES[i]` so the same labels render across lenses.
    • Kept body/soul metadata fields as placeholders until canonical mappings are provided (brainRegion, neurotransmitter, etc.).
    • No breaking API changes: export JSON schema is unchanged, but now includes the faculty names.

    Interaction model (current):
    • Click a node to focus + open details; drag sliders in the sidebar or modal to change activation (0–100).
    • Developmental Stage slider morphs all 32 activations using per‑aspect devProfile (12 stages, 0–11).
    • Tutorial mode cycles focus with a pulsing halo; Export downloads a reproducible state JSON.

    Suggested next UX increments (not yet implemented):
    • On‑canvas press+drag to adjust a node’s activation directly.
    • Quick preset chips (Flow, Deep Work, Social Sync, Recovery).
    • Search/filter the faculty list; pin two nodes for contrast; snapshot/undo.
    • Shareable state links (URL‑encoded state).
  -->
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>32 Aspect Developmental Self Clock — Mind–Body–Energy Mapping</title>
  <meta name="description" content="Interactive 32‑Aspect Self Clock for mind–body–energy mapping with exportable states and accessibility support." />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&display=swap" rel="stylesheet">
  <style>
    /* =============================================================
       32 Aspect Developmental Self Clock — Single File Implementation
       • Plain HTML, CSS, and JavaScript (no external libraries)
       • Accessible controls + Canvas visualization
       • Keyboard navigation, high-contrast defaults, mobile-friendly
       ============================================================= */

    :root {
      --bg: #0a0c1a;
      --panel: #10152b;
      --ink: #e9ecf8;
      --muted: #9ca7c5;
      --accent: #00c6ff;   /* cyan electric */
      --accent-2: #8b5cf6; /* violet vivid */
      --good: #10b981;     /* emerald */
      --warn: #fbbf24;     /* amber */
      --bad: #ef4444;      /* red */
      --ring: #1f2543;
      --focus: #fde68a;
      --glow: rgba(0, 198, 255, 0.2);
    }

    * { box-sizing: border-box; }
    html, body { height: 100%; }

    @keyframes breathe {
      0%, 100% {
        background-position: 50% 50%;
      }
      50% {
        background-position: 48% 52%;
      }
    }

    body {
      margin: 0;
      font-family: 'Inter', 'Segoe UI', Roboto, system-ui, sans-serif;
      color: var(--ink);
      font-size: 15px;
      line-height: 1.5;
      letter-spacing: 0.2px;
      background: radial-gradient(1200px 1200px at 70% 20%, #141a3a 0%, var(--bg) 60%);
      background-size: 200% 200%;
      animation: breathe 18s ease-in-out infinite;
    }

    h1, h2, h3, strong {
      color: var(--ink);
      letter-spacing: 0.4px;
    }

    .app {
      display: grid;
      grid-template-columns: 1fr 360px;
      grid-template-rows: auto 1fr auto;
      grid-template-areas: 
        "top top"
        "vis side"
        "footer footer";
      gap: 12px;
      height: 100dvh;
      padding: 10px;
    }

    header {
      grid-area: top;
      display: flex;
      flex-wrap: wrap;
      align-items: center;
      justify-content: space-between;
      gap: 8px;
      background: linear-gradient(135deg, rgba(16, 24, 48, 0.92), rgba(12, 18, 36, 0.85));
      border: 1px solid rgba(28, 36, 82, 0.75);
      border-radius: 14px;
      padding: 10px 12px;
      box-shadow: 0 12px 35px rgba(0,0,0,0.35);
      backdrop-filter: blur(10px);
    }

    header h1 { font-size: clamp(16px, 2vw, 18px); margin: 0; letter-spacing: .3px; }

    header .controls { display: flex; flex-wrap: wrap; align-items: center; gap: 8px; }

    .btn {
      background: linear-gradient(180deg, #1a254d, #0f162f);
      color: var(--ink);
      border: 1px solid #2c3e75;
      border-radius: 10px;
      padding: 8px 12px;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.2s ease;
      box-shadow: 0 2px 6px rgba(0,0,0,0.3);
    }
    .btn:hover {
      background: linear-gradient(180deg, #223371, #1b2754);
      border-color: var(--accent);
      box-shadow: 0 0 8px var(--glow);
    }
    .btn:focus-visible { outline: 3px solid var(--focus); outline-offset: 2px; }
    .btn.secondary { opacity: 0.8; }
    .btn.warn { background: #3b1f1f; border-color: #6b2b2b; }

    body.modal-open { overflow: hidden; }

    .tutorial-modal {
      position: fixed;
      inset: 0;
      display: flex;
      align-items: center;
      justify-content: center;
      padding: 24px;
      opacity: 0;
      pointer-events: none;
      transition: opacity 0.35s ease;
      z-index: 120;
    }

    .tutorial-modal.is-visible {
      opacity: 1;
      pointer-events: auto;
    }

    .tutorial-modal__backdrop {
      position: absolute;
      inset: 0;
      background: rgba(8, 13, 30, 0.72);
      backdrop-filter: blur(6px);
      opacity: 0;
      transition: opacity 0.35s ease;
    }

    .tutorial-modal.is-visible .tutorial-modal__backdrop {
      opacity: 1;
    }

    .tutorial-modal__panel {
      position: relative;
      max-width: min(560px, 100%);
      background: linear-gradient(150deg, rgba(22, 28, 56, 0.96), rgba(14, 18, 40, 0.94));
      border: 1px solid rgba(64, 90, 170, 0.5);
      border-radius: 18px;
      padding: clamp(20px, 4vw, 32px);
      box-shadow: 0 28px 80px rgba(0, 0, 0, 0.45);
      color: var(--ink);
      transform: translateY(12px) scale(0.98);
      transition: transform 0.35s ease;
    }

    .tutorial-modal.is-visible .tutorial-modal__panel {
      transform: translateY(0) scale(1);
    }

    .tutorial-modal__close {
      position: absolute;
      top: 14px;
      right: 14px;
      background: transparent;
      border: none;
      color: var(--muted);
      font-size: 20px;
      cursor: pointer;
      transition: color 0.2s ease;
    }

    .tutorial-modal__close:hover,
    .tutorial-modal__close:focus-visible {
      color: var(--accent);
      outline: none;
    }

    .tutorial-modal h2 {
      margin-top: 0;
      font-size: clamp(22px, 3.4vw, 26px);
      letter-spacing: 0.5px;
    }

    .tutorial-modal p {
      margin: 0 0 12px 0;
      color: rgba(233, 236, 248, 0.92);
    }

    .tutorial-modal__stage {
      margin-top: 20px;
      padding: 16px;
      border-radius: 14px;
      background: linear-gradient(170deg, rgba(24, 32, 64, 0.85), rgba(18, 24, 48, 0.9));
      border: 1px solid rgba(66, 90, 170, 0.4);
      box-shadow: inset 0 0 18px rgba(0, 0, 0, 0.3);
    }

    .tutorial-modal__stage h3 {
      margin-top: 0;
      margin-bottom: 4px;
      font-size: 18px;
      letter-spacing: 0.4px;
    }

    .tutorial-modal__focus {
      font-weight: 600;
      color: var(--accent);
    }

    .tutorial-modal__muted {
      color: rgba(156, 167, 197, 0.85);
      font-size: 13px;
      letter-spacing: 0.3px;
    }

    .tutorial-modal__divider {
      width: 100%;
      height: 1px;
      background: linear-gradient(90deg, transparent, rgba(138, 92, 246, 0.4), transparent);
      margin: 16px 0;
    }

    .vis {
      grid-area: vis;
      position: relative;
      background: radial-gradient(900px 900px at 50% 40%, rgba(16, 25, 52, 0.95) 0%, rgba(5, 9, 20, 0.95) 60%);
      border-radius: 16px;
      border: 1px solid rgba(28, 36, 82, 0.85);
      display: grid;
      grid-template-rows: 1fr auto;
      overflow: clip;
      box-shadow: 0 25px 60px rgba(0,0,0,0.35);
    }

    canvas {
      width: 100%;
      height: 100%;
      display: block;
      filter: drop-shadow(0 0 8px rgba(0, 198, 255, 0.25));
      transition: filter 0.3s ease;
    }

    canvas:focus-visible {
      filter: drop-shadow(0 0 12px rgba(253, 230, 138, 0.5));
    }

    .legend {
      padding: 10px;
      border-top: 1px solid #1b1f3f;
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      align-items: center;
      background: rgba(12, 17, 38, 0.8);
      backdrop-filter: blur(8px);
      box-shadow: inset 0 0 10px rgba(255,255,255,0.04);
    }

    .legend .chip {
      display: inline-flex; align-items: center; gap: 6px;
      border: 1px solid rgba(44, 62, 117, 0.7);
      border-radius: 999px;
      padding: 6px 10px;
      color: var(--muted);
      background: linear-gradient(135deg, rgba(17, 25, 50, 0.9), rgba(20, 35, 68, 0.75));
      font-size: 12px;
      transition: transform 0.2s ease, box-shadow 0.2s ease;
      box-shadow: 0 2px 6px rgba(0,0,0,0.25);
    }

    .legend .chip:hover {
      transform: translateY(-1px);
      box-shadow: 0 4px 10px rgba(0,0,0,0.35);
    }

    .legend .swatch { width: 12px; height: 12px; border-radius: 3px; background: var(--accent); display: inline-block; }

    aside {
      grid-area: side;
      display: grid;
      grid-template-rows: auto 1fr auto;
      gap: 10px;
      background: linear-gradient(145deg, rgba(13, 19, 38, 0.92), rgba(9, 13, 28, 0.88));
      border: 1px solid rgba(26, 36, 80, 0.75);
      border-radius: 16px;
      padding: 10px;
      overflow: hidden;
      box-shadow: 0 20px 50px rgba(0,0,0,0.35);
      backdrop-filter: blur(10px);
    }

    .panel {
      background: rgba(16, 21, 43, 0.85);
      border: 1px solid #1b214b;
      border-radius: 14px;
      padding: 12px;
      backdrop-filter: blur(8px);
      box-shadow: inset 0 0 12px rgba(255,255,255,0.03), 0 0 18px rgba(0,0,0,0.4);
    }

    .metrics { display: grid; grid-template-columns: 1fr 1fr; gap: 8px; }

    .metric {
      background: rgba(8, 12, 26, 0.8);
      border: 1px solid #1c254b;
      border-radius: 12px;
      padding: 10px;
      box-shadow: 0 0 8px rgba(0,0,0,0.25);
    }
    .metric h3 { margin: 0 0 6px; font-size: 12px; color: var(--muted); font-weight: 600; }
    .metric .val { font-size: 18px; font-weight: 800; color: var(--accent); }

    .scroll { overflow: auto; min-height: 120px; max-height: 50vh; padding-right: 4px; }
    .aspect-list { display: grid; gap: 6px; }

    .aspect-item {
      background: rgba(10, 15, 30, 0.82);
      border: 1px solid rgba(32, 44, 96, 0.8);
      border-radius: 12px;
      padding: 8px;
      display: grid;
      gap: 6px;
      transition: border-color 0.2s ease, box-shadow 0.2s ease, transform 0.2s ease;
      box-shadow: 0 6px 14px rgba(0,0,0,0.25);
    }
    .aspect-item:hover {
      border-color: var(--accent);
      box-shadow: 0 10px 20px rgba(0, 198, 255, 0.15);
      transform: translateY(-1px);
    }
    .aspect-item[aria-selected="true"] { outline: 2px solid var(--focus); }
    .row { display: flex; gap: 8px; align-items: center; justify-content: space-between; }
    .row .name { display: flex; align-items: center; gap: 8px; font-weight: 700; }
    .dot { width: 10px; height: 10px; border-radius: 999px; }
    .tags { display: flex; gap: 6px; flex-wrap: wrap; }
    .tag {
      font-size: 10px;
      color: var(--muted);
      background: rgba(20, 29, 58, 0.85);
      border: 1px solid rgba(46, 66, 132, 0.7);
      padding: 2px 6px;
      border-radius: 999px;
      transition: background 0.2s ease;
    }
    .tag:hover { background: rgba(32, 49, 98, 0.95); }

    label { font-size: 12px; color: var(--muted); }
    input[type="range"] { width: 100%; }
    input[type="range"]:focus-visible { outline: 2px solid var(--focus); }

    footer {
      grid-area: footer;
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      align-items: center;
      justify-content: space-between;
      background: linear-gradient(135deg, rgba(11, 16, 32, 0.9), rgba(8, 12, 26, 0.85));
      border-top: 1px solid rgba(28, 40, 90, 0.6);
      padding: 8px 10px;
      border-radius: 12px;
      box-shadow: 0 -2px 20px rgba(0,0,0,0.3);
      backdrop-filter: blur(8px);
    }

    .vis-hint { color: var(--muted); font-size: 12px; }

    .narrative-box {
      margin: 10px;
      padding: 10px;
      border-radius: 14px;
      background: color-mix(in oklab, var(--panel) 85%, black 15%);
      border: 1px solid #1c2248;
      box-shadow: 0 4px 18px rgba(0, 0, 0, 0.35);
    }

    .narrative-box label {
      display: block;
      font-weight: 700;
      margin-bottom: 6px;
    }

    .narrative-box textarea {
      width: 100%;
      min-height: 320px;
      background: #0a0f24;
      color: var(--ink);
      border: 1px solid #1a2352;
      border-radius: 12px;
      padding: 12px;
      font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
      font-size: 12px;
      line-height: 1.4;
      resize: vertical;
    }

    .narrative-box textarea:focus-visible {
      outline: 2px solid var(--focus);
      outline-offset: 3px;
    }

    /* Dialog (for quick info/tooltip-like modal) */
    dialog {
      border: 1px solid rgba(44, 62, 117, 0.7);
      border-radius: 16px;
      padding: 0;
      color: var(--ink);
      background: rgba(12, 18, 36, 0.95);
      max-width: min(520px, 92vw);
      backdrop-filter: blur(12px);
      box-shadow: 0 20px 60px rgba(0,0,0,0.45);
    }
    dialog::backdrop { background: rgba(4, 6, 14, 0.65); }
    .modal-head {
      padding: 12px;
      border-bottom: 1px solid rgba(46, 66, 132, 0.5);
      display: flex;
      align-items: center;
      justify-content: space-between;
      background: linear-gradient(135deg, rgba(18, 26, 52, 0.9), rgba(20, 34, 68, 0.8));
    }
    .modal-body { padding: 12px; display: grid; gap: 10px; }
    .modal-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 8px; }
    .modal-grid > div {
      background: rgba(10, 15, 30, 0.85);
      border: 1px solid rgba(32, 44, 96, 0.7);
      border-radius: 10px;
      padding: 8px;
      box-shadow: inset 0 0 10px rgba(255,255,255,0.02);
    }

    /* Stage tutorial modal */
    .stage-modal {
      position: fixed;
      inset: 0;
      display: flex;
      align-items: center;
      justify-content: center;
      visibility: hidden;
      opacity: 0;
      pointer-events: none;
      transition: opacity 300ms cubic-bezier(0.16, 1, 0.3, 1);
      z-index: 1200;
    }

    .stage-modal.active {
      visibility: visible;
      opacity: 1;
      pointer-events: auto;
    }

    .stage-modal__overlay {
      position: absolute;
      inset: 0;
      background: rgba(0, 0, 0, 0.6);
      backdrop-filter: blur(4px);
    }

    .stage-modal__content {
      position: relative;
      width: min(620px, 92vw);
      max-height: 85vh;
      overflow-y: auto;
      padding: 28px;
      background: linear-gradient(135deg, rgba(16, 22, 44, 0.95), rgba(9, 13, 28, 0.92));
      border-radius: 18px;
      border: 1px solid rgba(44, 70, 128, 0.65);
      box-shadow: 0 26px 70px rgba(0, 0, 0, 0.45);
      animation: stageModalSlideIn 300ms cubic-bezier(0.16, 1, 0.3, 1);
    }

    .stage-modal__title {
      margin: 0 0 16px;
      font-size: 1.4rem;
      color: var(--ink);
    }

    .stage-modal__body {
      color: var(--muted);
      line-height: 1.6;
    }

    .stage-modal__body p {
      margin: 0 0 12px;
    }

    .stage-modal__body p:last-child {
      margin-bottom: 0;
    }

    .stage-modal__close {
      position: absolute;
      top: 16px;
      right: 16px;
      border: none;
      background: transparent;
      color: var(--muted);
      font-size: 1.6rem;
      cursor: pointer;
      transition: color 150ms ease;
    }

    .stage-modal__close:hover,
    .stage-modal__close:focus-visible {
      color: var(--ink);
    }

    .stage-modal__highlight {
      color: var(--ink);
      font-weight: 600;
    }

    .stage-modal__footnote {
      font-size: 0.9rem;
      color: #cbd5f5;
      border-top: 1px solid rgba(78, 102, 162, 0.35);
      padding-top: 12px;
      margin-top: 12px;
    }

    @keyframes stageModalSlideIn {
      from {
        transform: translateY(-18px) scale(0.96);
        opacity: 0;
      }
      to {
        transform: translateY(0) scale(1);
        opacity: 1;
      }
    }

    @media (max-width: 1024px) {
      .app { grid-template-columns: 1fr; grid-template-areas: "top" "vis" "side" "footer"; height: auto; min-height: 100dvh; }
      aside { order: 3; }
    }
  </style>
</head>
<body>
  <a href="semantic_physics_outline.html">
  <button class="btn">View Semantic Physics Outline</button>
</a>

  <section class="narrative-box" aria-label="Self-Clock Architecture narrative">
    <label for="selfClockNarrative">Self-Clock Architecture Brief</label>
    <textarea id="selfClockNarrative" readonly spellcheck="false">
Welcome to the Self-Clock Architecture
A Living Framework for Harmonic Human Development

You are entering the Self-Clock Architecture, an interactive model born from the Semantic Physics framework.
This system is more than a visual design — it’s a new language for understanding human growth, rhythm, and transformation.

At its heart lies the 12-Stage, 24-Hour Developmental Model — a pioneering structure that maps psychological and emotional evolution across time.
It transforms what we traditionally think of as “developmental stages” into dynamic patterns of harmonic resonance, where growth is measured not by conflict, but by coherence.

I. A New Way to Understand Growth: Temporal Resonance Architecture

Most developmental theories describe growth as a series of conflicts to be resolved.
The Self-Clock takes a very different approach: it models development as a symphony of frequencies coming into tune.

Beyond Binary Conflict
Rather than defining progress through opposing tensions like “trust versus mistrust,” the Self-Clock describes development as a continuous harmonic field. Growth is not struggle; it’s resonance.

Harmonic Field Theory
Each stage represents a frequency within a greater resonance field. When the fields synchronize, psychological health emerges — much like a well-tuned instrument finding its tone.

Temporal Integration
The model operates on a 24-hour cycle, grounding the abstract concept of development in the daily rhythm of life — illustrating that growth happens in time, through time, and with time.

II. The Structure: Stages and Aspectual Rings

The Self-Clock organizes consciousness into a living, multi-dimensional matrix that you can actually see and interact with.

Twelve Developmental Stages:
Each two-hour segment of the 24-hour cycle represents a distinct stage of psychological growth — from foundational security and self-generation to transcendence and renewal.

Foundation Stages: Imprinting (12–2), Autogenic (2–4)

Mid-Cycle Stages: Intentional (4–6), Competence (6–8), Mirror (8–10), Bonding (10–12)

Integrative Stages: Generative (12–14), Integration (14–16), Reflection (16–18)

Transcendental Stages: Transcendence (18–20), Unity (20–22), Return (22–24)

Eight Aspectual Rings:
Each stage operates through eight dimensions of functioning — from perception and memory to emotion and meaning-making — creating a 32-aspect field.
Together, they form the Self-Clock’s distinctive 32-dimensional developmental geometry.

III. The Science Behind the Symbol

Beneath its elegance, the Self-Clock rests on mathematical foundations that allow subjective experience to be expressed in measurable form.

Resonance Equation:
Developmental transitions are expressed as changes in resonance over time:

R_{n+1} = f(R_n, Δt, ψ, Φ_field)

where progress depends on time (Δt), internal intention (ψ), and the surrounding field (Φ_field).

Trauma Integration:
Through Semantic Gravity Theory, trauma is represented as added mass within the field — a curvature that requires greater intention (ψ) to achieve equilibrium.
This gives the model real predictive power: it can quantify resilience and reveal how healing alters a person’s resonance field.

IV. Validation and Integration

The Self-Clock isn’t hypothetical — it emerged from 18 months of continuous fieldwork during the Survival as Method project, in which 131 developmental cycles were recorded and analyzed under high-stress, high-data conditions.
The system’s predictive coherence reached over 96% accuracy for one-hour forecasts, confirming that harmonic resonance can indeed model psychological dynamics.

Today, the Self-Clock serves as the temporal-cognitive foundation for the broader Semantic Physics architecture:

MoodSphere: maps emotional energy within a six-dimensional affective field (gravity, recurrence, affective charge, etc.).

QITP & NSIL: convert developmental data into therapeutic and cognitive protocols for real-world application.

Eidolon Protocol: ensures temporal and developmental coherence in reconstituted or evolving consciousness models.

V. A Living Map of the Human Spirit

Think of the Self-Clock as a dynamic computational mirror — a system that translates subjective will and environmental influence into mathematically predictable harmony.
It’s both a tool and a meditation: a way to visualize balance, growth, and transformation in real time.

Whether you approach it as a scientist, a philosopher, or simply as a human being curious about your own evolution, the Self-Clock invites you to watch your consciousness move in rhythm — to see development not as a ladder, but as a waveform of becoming.
</textarea>
  </section>

  <div class="app" role="application" aria-label="32 Aspect Developmental Self Clock">
    <header>
      <h1>32 Aspect Self Clock · Mind–Body–Energy Mapping</h1>
      <div class="controls">
        <button id="modeMind" class="btn" aria-pressed="true" title="View Mind model (psych/semantic)">Mind</button>
        <button id="modeBody" class="btn secondary" aria-pressed="false" title="View Body model (neuro/physiology)">Body</button>
        <button id="modeSoul" class="btn secondary" aria-pressed="false" title="View Soul model (archetypal/transpersonal)">Soul</button>
        <button id="tutorialBtn" class="btn secondary" aria-label="Open Self-Clock tutorial">Tutorial</button>
        <button id="btnTutorialMode" class="btn" aria-pressed="false" title="Toggle tutorial/walkthrough mode (keyboard: T)">▶ Tutorial Mode</button>
        <button id="btnRandomize" class="btn secondary" title="Randomize activations (keyboard: R)">Shuffle</button>
        <button id="btnDeactivate" class="btn secondary" title="Set all activations to 0 (keyboard: 0)">Deactivate All</button>
        <button id="btnExport" class="btn" title="Export all aspect states as JSON (keyboard: E)">Export JSON</button>
      </div>
    </header>

    <section class="vis">
      <canvas id="clockCanvas" aria-label="Developmental Self Clock canvas" tabindex="0"></canvas>
      <script type="module">
        import definitions from './data/self_clock_definitions.json' assert {type: 'json'};

        const canvas = document.getElementById('clockCanvas');     // your main canvas id
        const tooltip = document.createElement('div');
        tooltip.id = 'aspectTooltip';
        tooltip.style.position = 'absolute';
        tooltip.style.display = 'none';
        tooltip.style.background = 'rgba(255,255,255,0.95)';
        tooltip.style.border = '1px solid #ccc';
        tooltip.style.borderRadius = '8px';
        tooltip.style.padding = '0.75rem';
        tooltip.style.maxWidth = '260px';
        tooltip.style.fontSize = '0.85rem';
        tooltip.style.lineHeight = '1.2rem';
        tooltip.style.boxShadow = '0 2px 10px rgba(0,0,0,0.15)';
        tooltip.style.zIndex = 50;
        document.body.appendChild(tooltip);

        // assume you already have an array of aspect objects with x, y, name
        let aspects = window.aspects || [];  // import or generate them in your clock code
        window.addEventListener('selfClockAspectsUpdated', () => {
          aspects = window.aspects || [];
        });

        function showTooltip(aspect, x, y) {
          const data = definitions[aspect.name];
          if (!data) return;

          tooltip.innerHTML = `
            <strong>${aspect.name}</strong><br>
            <em>${data.definition}</em><br><br>
            <b>Functional role:</b> ${data.functional_role}<br>
            <b>Symbolic resonance:</b> ${data.symbolic_resonance}<br>
            <b>Example:</b> ${data.example}
          `;
          tooltip.style.left = `${x + 12}px`;
          tooltip.style.top = `${y + 12}px`;
          tooltip.style.display = 'block';
        }

        function hideTooltip() {
          tooltip.style.display = 'none';
        }

        canvas.addEventListener('mousemove', e => {
          const rect = canvas.getBoundingClientRect();
          const x = e.clientX - rect.left;
          const y = e.clientY - rect.top;

          // simple hit-test; adjust radius to your aspect dot size
          const hit = aspects.find(a => Math.hypot(a.x - x, a.y - y) < 8);
          if (hit) {
            showTooltip(hit, e.pageX, e.pageY);
          } else {
            hideTooltip();
          }
        });

        canvas.addEventListener('mouseleave', hideTooltip);
      </script>
      <div class="legend" aria-label="Legend">
        <div class="chip"><span class="swatch" style="background: var(--accent)"></span> Stage cross-lines (12)</div>
        <div class="chip"><span class="swatch" style="background: var(--accent-2)"></span> Concentric rings (8)</div>
        <div class="chip"><span class="swatch" style="background: #34d399"></span> Resonance links (similar activation)</div>
        <div class="chip"><span class="swatch" style="background: #f59e0b"></span> Tutorial highlight</div>
      </div>
    </section>

    <aside>
      <div class="panel metrics" aria-label="System metrics">
        <div class="metric" aria-live="polite"><h3>SCI (Semantic Coherence Index)</h3><div class="val" id="sciVal">—</div></div>
        <div class="metric" aria-live="polite"><h3>Energy–Matter</h3><div class="val" id="emVal">—</div></div>
      </div>

      <div class="panel" aria-label="Developmental stage slider">
        <label for="devStageSlider"><strong>Developmental Stage</strong> <span id="devStageVal">1</span></label>
        <input id="devStageSlider" type="range" min="0" max="11" value="0" />
        <p class="vis-hint">0 = birth/infancy ··· 12 = wisdom/end-of-life · Adjusts all activations via devProfile</p>
      </div>

      <div class="panel scroll" aria-label="Aspect controls">
        <div id="aspectList" class="aspect-list" role="listbox" aria-multiselectable="false"></div>
      </div>

      <div class="panel" aria-label="Legend and codes">
        <div class="tags" style="margin-bottom:6px">
          <span class="tag">Brain: PFC, Limbic, Insula, Amygdala…</span>
          <span class="tag">NT: 5-HT, DA, NE, GABA, ACh, Oxytocin</span>
          <span class="tag">Modes: visual, auditory, interoceptive…</span>
        </div>
        <p class="vis-hint">Keyboard: Arrow keys pan focus · Enter opens details · T tutorial · R shuffle · E export · 0 clear</p>
      </div>
    </aside>

    <footer>
      <div class="vis-hint">C = E × MC · Energy input → neural region → neurochemical output → system response</div>
      <div class="vis-hint">Open science: Export preserves all annotations for reproducibility</div>
      <div class="vis-hint" aria-label="Attribution">© <span id="year"></span> Adrian Lei Martinez-Conol — founder of the Only When Prompted Research Initiative (2018)</div>
  </footer>
  </div>

  <!-- Stage tutorial modal -->
  <div id="tutorialModal" class="stage-modal" role="dialog" aria-labelledby="stageModalTitle" aria-modal="true" aria-hidden="true">
    <div id="tutorialModalOverlay" class="stage-modal__overlay"></div>
    <div class="stage-modal__content" role="document">
      <button id="closeTutorialModal" class="stage-modal__close" aria-label="Close tutorial window">&times;</button>
      <h2 id="stageModalTitle" class="stage-modal__title">Welcome to the Self-Clock</h2>
      <div id="stageModalBody" class="stage-modal__body">
        <p>The Self-Clock represents the harmonic rhythm of consciousness. Open the Tutorial at any time to understand how stage rhythms, neural signatures, and aspect focus converge.</p>
        <p class="stage-modal__footnote">Stage intelligence updates in real time as you explore the cycle.</p>
      </div>
    </div>
  </div>

  <div id="tutorialModal" class="tutorial-modal" role="dialog" aria-modal="true" aria-hidden="true">
    <div class="tutorial-modal__backdrop" data-dismiss="tutorial"></div>
    <div class="tutorial-modal__panel" role="document">
      <button type="button" class="tutorial-modal__close" data-dismiss="tutorial" aria-label="Close tutorial window">&times;</button>
      <h2>Welcome to the Self-Clock</h2>
      <p>Welcome to the Self-Clock. This framework maps the evolving harmony of consciousness through twelve stages of time and thirty-two aspects of awareness.</p>
      <p>Wherever you are in life, your development reflects a unique constellation of these aspects — the interplay between attention, memory, emotion, and meaning.</p>
      <p>Over the course of a lifetime, most people experience increasing overlap and communication between these aspects. As this happens, maturity deepens, and higher-order consciousness — insight, compassion, coherence — becomes more apparent.</p>
      <p>The Self-Clock doesn’t measure progress by success or failure. It shows the resonance between your inner frequencies — a living mirror of your psychological rhythm.</p>
      <div class="tutorial-modal__divider" aria-hidden="true"></div>
      <div class="tutorial-modal__stage">
        <h3 id="tutorialStageTitle">Stage: Imprinting (00:00–02:00)</h3>
        <p id="tutorialAspectFocus" class="tutorial-modal__focus">Aspect Focus: Awareness</p>
        <p id="tutorialStageSummary"></p>
        <p id="tutorialStageNarrative"></p>
        <p id="tutorialStageDynamic" class="tutorial-modal__muted"></p>
      </div>
    </div>
  </div>

  <!-- Info Modal (tooltip-like, accessible) -->
  <dialog id="infoModal" aria-label="Aspect details">
    <div class="modal-head">
      <strong id="mTitle">Aspect</strong>
      <button class="btn" value="cancel">Close</button>
    </div>
    <div class="modal-body">
      <div id="mDef" class="panel"></div>
      <div class="panel">
        <div><strong>Functional Role</strong></div>
        <div id="mFunctional"></div>
        <div style="margin-top:8px"><strong>Symbolic Resonance</strong></div>
        <div id="mSymbolic"></div>
        <div style="margin-top:8px"><strong>Illustrative Example</strong></div>
        <div id="mExample"></div>
      </div>
      <div class="modal-grid">
        <div>
          <div><strong>Brain Region(s)</strong></div>
          <div id="mBrain" aria-live="polite"></div>
        </div>
        <div>
          <div><strong>Neurochemistry</strong></div>
          <div id="mNT"></div>
        </div>
        <div>
          <div><strong>Energy Pathway / Sensory</strong></div>
          <div id="mEnergy"></div>
        </div>
        <div>
          <div><strong>Developmental Stage · Ring</strong></div>
          <div id="mStage"></div>
        </div>
      </div>
      <div class="panel">
        <label for="mSlider"><strong>Activation</strong> <span id="mActVal" style="float:right">0</span></label>
        <input id="mSlider" type="range" min="0" max="100" value="0" />
      </div>
      <div class="panel">
        <strong>Matter/Energy Summary</strong>
        <div id="mSummary"></div>
      </div>
    </div>
  </dialog>

  <script>
    /* ============================================================
       DATA MODEL
       ------------------------------------------------------------
       • Three model lenses: Mind / Body / Soul
       • Each lens has 32 aspects with a 12-point developmental profile
    ============================================================ */

    const N_ASPECTS = 32;
    const TWO_PI = Math.PI * 2;
    const center = { x: 0, y: 0 };
    const DEV_STAGES = 12;

    /* ============================================================
       CHANGELOG (for reviewers / toolchain)
       2025-10-16: Replace placeholder aspect labels with canonical faculties.
       - Added FACULTIES[] (clock order). All aspect names now come from this list.
       - makeAspectSet() uses name: FACULTIES[i].
       - Export payload unchanged; `aspects[].name` now equals a faculty label.
    ============================================================ */

    // Canonical 32 faculties of consciousness used for aspect labels (in clock order)
    const FACULTIES = [
      "Awareness",
      "Attention",
      "Perception (Visual)",
      "Perception (Auditory)",
      "Perception (Somatosensory)",
      "Interoception",
      "Proprioception",
      "Arousal / Vigilance",
      "Working Memory",
      "Episodic Memory",
      "Semantic Memory",
      "Language / Symbolics",
      "Imagination / Visualization",
      "Mental Time Travel",
      "Planning / Prospection",
      "Decision‑Making",
      "Inhibition / Self‑Control",
      "Cognitive Flexibility",
      "Meta‑awareness",
      "Self‑Model / Identity",
      "Emotion Processing",
      "Motivation / Drive",
      "Reward / Valuation",
      "Empathy / Theory of Mind",
      "Social Cognition",
      "Moral Reasoning",
      "Spatial Cognition",
      "Rhythm / Timing",
      "Creativity / Divergence",
      "Learning / Plasticity",
      "Dreaming / Imagery",
      "Narrative / Meaning‑Making"
    ];

    const STAGE_META = [
      {
        name: 'Imprinting',
        window: '00:00–02:00',
        aspectFocus: 'Awareness',
        aspectKey: FACULTIES[0],
        summary(focus) {
          return `During the Imprinting stage, consciousness is establishing its first rhythms. The ${focus} channel grounds you in immediate experience so the system can learn what safety feels like.`;
        },
        resonance() {
          return 'Everything is new input — the field is soft clay taking on the imprint of experience.';
        }
      },
      {
        name: 'Autogenic',
        window: '02:00–04:00',
        aspectFocus: 'Interoception',
        aspectKey: FACULTIES[5],
        summary(focus) {
          return `During the Autogenic stage, vitality gathers itself. The ${focus} channel helps you hear the body’s quiet signals so regulation can become self-directed.`;
        },
        resonance() {
          return 'Breath, pulse, and instinct synchronize, teaching how inner life responds when given space.';
        }
      },
      {
        name: 'Intentional',
        window: '04:00–06:00',
        aspectFocus: 'Attention',
        aspectKey: FACULTIES[1],
        summary(focus) {
          return `During the Intentional stage, will stirs awake. The ${focus} channel gives direction to emerging energy, turning impulse into aim.`;
        },
        resonance() {
          return 'Choices begin to sculpt the day, and action starts to speak in the language of meaning.';
        }
      },
      {
        name: 'Competence',
        window: '06:00–08:00',
        aspectFocus: 'Working Memory',
        aspectKey: FACULTIES[8],
        summary(focus) {
          return `During the Competence stage, practice meets structure. The ${focus} channel keeps effort coherent so skills can flow without friction.`;
        },
        resonance() {
          return 'Repetition turns into reliability, and confidence grows as systems hum together.';
        }
      },
      {
        name: 'Mirror',
        window: '08:00–10:00',
        aspectFocus: 'Self-Model / Identity',
        aspectKey: FACULTIES[19],
        summary(focus) {
          return `During the Mirror stage, consciousness looks at itself through relationship. The ${focus} channel reflects how identity is forming across every interaction.`;
        },
        resonance() {
          return 'Feedback becomes illumination, revealing the stories you live inside.';
        }
      },
      {
        name: 'Bonding',
        window: '10:00–12:00',
        aspectFocus: 'Empathy / Theory of Mind',
        aspectKey: FACULTIES[23],
        summary(focus) {
          return `During the Bonding stage, connection is the teacher. The ${focus} channel opens empathic pathways so resonance with others can settle deeply.`;
        },
        resonance() {
          return 'Shared rhythm nourishes the heart of the system, reminding you that growth is communal.';
        }
      },
      {
        name: 'Generative',
        window: '12:00–14:00',
        aspectFocus: 'Creativity / Divergence',
        aspectKey: FACULTIES[28],
        summary(focus) {
          return `During the Generative stage, momentum blooms outward. The ${focus} channel invites new combinations and ideas to spark.`;
        },
        resonance() {
          return 'It is a fertile interval where possibility multiplies and invention feels natural.';
        }
      },
      {
        name: 'Integration',
        window: '14:00–16:00',
        aspectFocus: 'Learning / Plasticity',
        aspectKey: FACULTIES[29],
        summary(focus) {
          return `During the Integration stage, patterns braid together. The ${focus} channel lets learning settle into lived wisdom.`;
        },
        resonance() {
          return 'The system cross-talks with ease, weaving insight into the fabric of daily movement.';
        }
      },
      {
        name: 'Reflection',
        window: '16:00–18:00',
        aspectFocus: 'Meta-Awareness',
        aspectKey: FACULTIES[18],
        summary(focus) {
          return `During the Reflection stage, consciousness turns inward to examine its own patterns. ${focus} heightens your ability to notice thought itself, recognizing meaning as both constructed and experienced.`;
        },
        resonance() {
          return 'This stage is a resting point — not an ending, but a deep inhalation before transformation.';
        }
      },
      {
        name: 'Transcendence',
        window: '18:00–20:00',
        aspectFocus: 'Dreaming / Imagery',
        aspectKey: FACULTIES[30],
        summary(focus) {
          return `During the Transcendence stage, awareness stretches beyond its usual frame. The ${focus} channel softens boundaries and lets symbolic imagery guide you.`;
        },
        resonance() {
          return 'What feels mysterious becomes an ally, pointing to meaning larger than the moment.';
        }
      },
      {
        name: 'Unity',
        window: '20:00–22:00',
        aspectFocus: 'Moral Reasoning',
        aspectKey: FACULTIES[25],
        summary(focus) {
          return `During the Unity stage, distinctions blur into harmony. The ${focus} channel tunes cooperative intelligence so coherence can be felt across the whole field.`;
        },
        resonance() {
          return 'You sense yourself as part of a larger pattern, and collaboration feels effortless.';
        }
      },
      {
        name: 'Return',
        window: '22:00–24:00',
        aspectFocus: 'Narrative / Meaning-Making',
        aspectKey: FACULTIES[31],
        summary(focus) {
          return `During the Return stage, consciousness circles back with new perspective. The ${focus} channel gives language to what was learned so it can be shared.`;
        },
        resonance() {
          return 'It is the exhale after a long journey — integrating insight and preparing the next cycle.';
        }
      }
    ];

    const FACULTY_DETAILS = [
      {
        definition: "Awareness denotes the baseline conscious registration of internal and external stimuli, reflecting widespread cortical integration of sensory and contextual information.",
        functionalRole: "It establishes the experiential field within which other cognitive operations unfold, enabling organisms to orient toward salient events.",
        symbolicResonance: "Stabilizes the Cx-field, harmonizing global conscious coherence with G-field presence.",
        example: "Noticing the ambient hum of a room while simultaneously sensing your posture and mood."
      },
      {
        definition: "Attention is the selective allocation of cognitive resources that amplifies relevant signals while suppressing distractors through fronto-parietal control networks.",
        functionalRole: "It prioritizes processing for goal-relevant stimuli, enhancing perception, working memory, and decision efficiency.",
        symbolicResonance: "Channels G-field focus into R-field alignment, producing directed engagement.",
        example: "Focusing on a lecturer’s voice despite background chatter."
      },
      {
        definition: "Visual perception transforms photic input into structured representations via hierarchical analysis in occipital-temporal pathways.",
        functionalRole: "It delivers spatial, object, and motion information critical for navigation, recognition, and planning.",
        symbolicResonance: "Maps the P-field with Cx-field clarity, projecting external form into internal schema.",
        example: "Recognizing a friend’s face across a crowded plaza."
      },
      {
        definition: "Auditory perception decodes acoustic waveforms into meaningful patterns through temporal cortex processing and auditory association circuits.",
        functionalRole: "It enables speech comprehension, environmental monitoring, and rhythmic entrainment.",
        symbolicResonance: "Infuses the P-field with T-field cadence, translating vibrational patterns into comprehension.",
        example: "Distinguishing a bird’s song and interpreting it as a sign of spring."
      },
      {
        definition: "Somatosensory perception integrates tactile, nociceptive, and temperature cues via the somatosensory cortex to represent bodily contact and surface states.",
        functionalRole: "It supports manipulation, protection, and embodiment by informing about touch, pain, and texture.",
        symbolicResonance: "Grounds the P-field in corporeal feedback, reinforcing the Id-field boundary.",
        example: "Feeling the warmth and grain of a wooden railing under your hand."
      },
      {
        definition: "Interoception is the monitoring of internal physiological signals such as heartbeat, respiration, and visceral states mediated by insular and brainstem circuits.",
        functionalRole: "It anchors emotional appraisal and homeostatic regulation, contributing to self-awareness.",
        symbolicResonance: "Binds the A-field with Cx-field coherence, harmonizing bodily sensation and conscious appraisal.",
        example: "Sensing your stomach tighten before giving a presentation."
      },
      {
        definition: "Proprioception is the perception of limb position and movement generated by muscle spindle and joint receptor input integrated in parietal cortices.",
        functionalRole: "It calibrates coordinated movement, posture, and spatial orientation without visual guidance.",
        symbolicResonance: "Couples the P-field with T-field stability, sustaining embodied alignment.",
        example: "Typing on a keyboard without looking at your hands."
      },
      {
        definition: "Arousal is the modulation of neural responsiveness by ascending reticular activating systems that set global alertness levels.",
        functionalRole: "It determines readiness for information processing and response, influencing attention and learning.",
        symbolicResonance: "Energizes the G-field, sustaining systemic activation across fields.",
        example: "Feeling alert and responsive after a sudden loud noise."
      },
      {
        definition: "Working memory is the limited-capacity system that transiently stores and manipulates information via prefrontal-parietal circuitry.",
        functionalRole: "It supports reasoning, language comprehension, and goal-directed behavior by holding task-relevant content online.",
        symbolicResonance: "Maintains structured R-field sequences within the Cx-field nexus.",
        example: "Remembering a phone number long enough to dial it."
      },
      {
        definition: "Episodic memory encodes and retrieves autobiographical events through hippocampal-cortical interactions, retaining temporal-spatial context.",
        functionalRole: "It enables reconstruction of past experiences to guide identity and future planning.",
        symbolicResonance: "Weaves Id-field narrative threads across T-field chronology.",
        example: "Recalling the details of your last vacation."
      },
      {
        definition: "Semantic memory stores decontextualized knowledge about facts, concepts, and language supported by distributed neocortical networks.",
        functionalRole: "It provides conceptual frameworks that ground understanding and inference.",
        symbolicResonance: "Stabilizes the Cx-field lattice with R-field conceptual structure.",
        example: "Knowing that Paris is the capital of France."
      },
      {
        definition: "Language processing orchestrates phonological, syntactic, and semantic operations across perisylvian cortex to encode and decode symbolic communication.",
        functionalRole: "It enables abstract thought, interpersonal exchange, and cultural transmission.",
        symbolicResonance: "Transduces R-field codes through the Cx-field medium into shared meaning.",
        example: "Formulating a sentence to explain your reasoning during a debate."
      },
      {
        definition: "Imagination recruits default mode and visual association networks to simulate sensory experiences without current external input.",
        functionalRole: "It allows mental rehearsal, creative ideation, and hypothesis testing.",
        symbolicResonance: "Projects Cx-field constructs into P-field imagery, expanding potential states.",
        example: "Mentally picturing how furniture will look in a new apartment."
      },
      {
        definition: "Mental time travel is the capacity to reconstruct past events and pre-experience future scenarios by flexibly navigating episodic representations.",
        functionalRole: "It supports planning, learning from experience, and maintaining autobiographical continuity.",
        symbolicResonance: "Traverses T-field arcs, synchronizing Id-field continuity across time.",
        example: "Reliving a childhood memory while anticipating how a reunion might unfold."
      },
      {
        definition: "Planning involves prefrontal circuitry generating ordered action sequences to achieve future goals based on predictive models.",
        functionalRole: "It organizes behavior over time, allocating resources and contingencies.",
        symbolicResonance: "Aligns R-field strategy with T-field foresight, informing Cx-field directives.",
        example: "Mapping out tasks and deadlines to complete a project on schedule."
      },
      {
        definition: "Decision-making integrates value, risk, and outcome representations via prefrontal, striatal, and limbic systems to select actions.",
        functionalRole: "It resolves competing options to guide behavior toward desired ends.",
        symbolicResonance: "Balances N-field evaluation with A-field salience, yielding Cx-field choice.",
        example: "Weighing job offers by comparing salary, location, and growth opportunities."
      },
      {
        definition: "Inhibition is the top-down suppression of prepotent responses mediated by prefrontal control networks.",
        functionalRole: "It prevents impulsive actions, enabling goal-consistent behavior.",
        symbolicResonance: "Moderates A-field impulses within the R-field governance lattice.",
        example: "Resisting the urge to check your phone during a meeting."
      },
      {
        definition: "Cognitive flexibility is the ability to adapt thinking and behavior in response to shifting rules or perspectives, driven by fronto-striatal circuits.",
        functionalRole: "It enables problem-solving, creativity, and resilience to change.",
        symbolicResonance: "Allows smooth transitions across R-field configurations while preserving Cx-field coherence.",
        example: "Switching strategies when a familiar approach fails during a puzzle."
      },
      {
        definition: "Meta-awareness involves monitoring one’s own cognitive and affective states, supported by anterior prefrontal and insular regions.",
        functionalRole: "It facilitates self-regulation, error detection, and mindful recalibration.",
        symbolicResonance: "Creates a reflective loop within the Cx-field, surveying G-field dynamics.",
        example: "Noticing that your attention has wandered during meditation and gently returning focus."
      },
      {
        definition: "The self-model is the integrated representation of personal traits, memories, and roles maintained by medial prefrontal and temporoparietal networks.",
        functionalRole: "It organizes autobiographical continuity and guides social positioning.",
        symbolicResonance: "Consolidates the Id-field framework anchored through Cx-field narratives.",
        example: "Recognizing yourself as a caregiver and interpreting actions through that lens."
      },
      {
        definition: "Emotion processing interprets and responds to affective stimuli through limbic-prefrontal interactions, mapping valence and arousal states.",
        functionalRole: "It shapes adaptive responses, decision biases, and social signaling.",
        symbolicResonance: "Activates the A-field, modulating all other fields via affective tone.",
        example: "Feeling relief after resolving a conflict and adjusting future interactions."
      },
      {
        definition: "Motivation arises from mesolimbic dopaminergic circuits signaling incentive salience and goal pursuit tendencies.",
        functionalRole: "It energizes behavior, sustaining efforts toward desired outcomes.",
        symbolicResonance: "Charges the N-field vectors, propelling action through the G-field.",
        example: "Persisting with training because you anticipate improvement before a competition."
      },
      {
        definition: "Reward processing evaluates outcomes and reinforces behaviors via orbitofrontal-striatal computations of expected value.",
        functionalRole: "It shapes learning, preference formation, and adaptive choice.",
        symbolicResonance: "Tunes N-field valence gradients, informing R-field prioritization.",
        example: "Experiencing satisfaction after completing a challenging task, reinforcing future effort."
      },
      {
        definition: "Empathy and theory of mind comprise the ability to infer others’ emotions and mental states via temporoparietal and medial prefrontal networks.",
        functionalRole: "They facilitate social understanding, cooperation, and moral alignment.",
        symbolicResonance: "Bridges Id-field selfhood with social Cx-field harmonics.",
        example: "Sensing a friend’s disappointment despite their polite smile and offering support."
      },
      {
        definition: "Social cognition encompasses the perception, interpretation, and prediction of social cues and group dynamics through specialized cortical and subcortical systems.",
        functionalRole: "It guides interpersonal behavior, status navigation, and cultural learning.",
        symbolicResonance: "Interlaces R-field schemas with G-field collective resonance.",
        example: "Reading the room during a meeting and adjusting your tone accordingly."
      },
      {
        definition: "Moral reasoning evaluates actions against ethical norms, engaging prefrontal, temporoparietal, and limbic structures to balance harm, fairness, and intent.",
        functionalRole: "It governs value-based choices and social accountability.",
        symbolicResonance: "Aligns N-field valuation with T-field karmic trajectories within the Cx-field.",
        example: "Choosing to return a lost wallet because it feels ethically obligatory."
      },
      {
        definition: "Spatial cognition constructs mental maps and orientation using parietal and hippocampal circuitry to encode metric and relational properties of environments.",
        functionalRole: "It supports navigation, object manipulation, and spatial reasoning.",
        symbolicResonance: "Extends P-field geometry through T-field pathways for embodied presence.",
        example: "Mentally plotting the fastest route through a city to reach a destination."
      },
      {
        definition: "Rhythm and timing perception coordinates temporal patterns via cerebellar, basal ganglia, and cortical synchrony.",
        functionalRole: "It underlies motor coordination, speech, and entrainment to external beats.",
        symbolicResonance: "Synchronizes T-field pulses with P-field sequencing.",
        example: "Keeping tempo with a metronome while playing an instrument."
      },
      {
        definition: "Creativity involves generating novel, valuable ideas through interplay between default mode, executive control, and salience networks.",
        functionalRole: "It expands problem-solving repertoires and cultural innovation.",
        symbolicResonance: "Invokes divergent Cx-field branching informed by P-field recombination.",
        example: "Combining disparate concepts to design an original product."
      },
      {
        definition: "Learning reflects experience-dependent neural plasticity, altering synaptic strengths and network configurations across cortical and subcortical regions.",
        functionalRole: "It encodes new knowledge and adapts behavior through reinforcement and consolidation.",
        symbolicResonance: "Adjusts N-field gradients and R-field structures, refining the Self-Clock lattice.",
        example: "Improving performance after repeated practice of a skill."
      },
      {
        definition: "Dreaming is the spontaneous generation of perceptual narratives during sleep, driven by intrinsic activity in limbic and associative cortices with reduced executive constraint.",
        functionalRole: "It may support memory consolidation, emotional processing, and creative integration.",
        symbolicResonance: "Unbounded Cx-field simulations traverse T-field and P-field interplay.",
        example: "Experiencing a vivid nighttime scenario that blends memories with fantastical elements."
      },
      {
        definition: "Narrative construction integrates events into coherent stories through default mode network operations linking episodic and semantic memory.",
        functionalRole: "It confers meaning, organizes identity, and communicates experience.",
        symbolicResonance: "Weaves Id-field continuity with Cx-field articulation across T-field arcs.",
        example: "Reflecting on a challenging period and framing it as a turning point in personal growth."
      }
    ];

    // Placeholders; replace with canonical mappings as needed
    const BRAIN = ["PFC", "Limbic", "Insula", "Amygdala", "Hippocampus", "ACC", "Basal Ganglia", "Cerebellum"];
    const NT = ["Serotonin (5-HT)", "Dopamine (DA)", "Norepinephrine (NE)", "GABA", "Acetylcholine (ACh)", "Oxytocin", "Endorphins"];
    const MODES = ["visual", "auditory", "somatosensory", "interoceptive", "proprioceptive", "olfactory"];

    const STAGE_DETAILS = [
      {
        index: 0,
        stage: 'Imprinting',
        timeWindow: '00:00–02:00',
        primaryAspect: 'Interoception',
        neuralCorrelates: 'Brainstem–autonomic loops, anterior insula synchronisation',
        description: 'During Imprinting, the system orients around foundational safety signals and somatic attunement. Consistent cues calibrate interoceptive baselines and create the felt sense of belonging from which later differentiation can emerge.'
      },
      {
        index: 1,
        stage: 'Autogenic',
        timeWindow: '02:00–04:00',
        primaryAspect: 'Arousal / Vigilance',
        neuralCorrelates: 'Locus coeruleus modulation with thalamic gating and cortical upshifts',
        description: 'Autogenic consolidates self-generated regulation. Oscillatory arousal patterns stabilise so the organism can initiate action without external prompts, translating survival energy into agency.'
      },
      {
        index: 2,
        stage: 'Intentional',
        timeWindow: '04:00–06:00',
        primaryAspect: 'Attention',
        neuralCorrelates: 'Dorsal attention network synchrony, superior parietal–prefrontal coupling',
        description: 'Intentional redirects awareness toward goal selection and preparatory focus. Attentional gating sharpens priorities while early executive circuits rehearse desired trajectories.'
      },
      {
        index: 3,
        stage: 'Competence',
        timeWindow: '06:00–08:00',
        primaryAspect: 'Working Memory',
        neuralCorrelates: 'Frontoparietal control network coherence, dorsolateral prefrontal–cerebellar loops',
        description: 'Competence strengthens capacity to hold and refine complex operations. Working memory scaffolds skill acquisition, translating practice into reliable performance signatures.'
      },
      {
        index: 4,
        stage: 'Mirror',
        timeWindow: '08:00–10:00',
        primaryAspect: 'Empathy / Theory of Mind',
        neuralCorrelates: 'Temporoparietal junction and medial prefrontal resonance, superior temporal sulcus mirroring',
        description: 'Mirror invites reciprocal awareness and social reflection. Sensitivity to others’ signals refines self-concept and sets the stage for empathic attunement.'
      },
      {
        index: 5,
        stage: 'Bonding',
        timeWindow: '10:00–12:00',
        primaryAspect: 'Emotion Processing',
        neuralCorrelates: 'Limbic–prefrontal coupling with oxytocinergic modulation and vagal tone shifts',
        description: 'Bonding grounds belonging through affective exchange. Emotional regulation synchronises across partners, reinforcing trust and broadening the system’s tolerance for vulnerability.'
      },
      {
        index: 6,
        stage: 'Generative',
        timeWindow: '12:00–14:00',
        primaryAspect: 'Creativity / Divergence',
        neuralCorrelates: 'Default–executive coupling with salience network gating of associative novelty',
        description: 'Generative opens the field to novelty and experimentation. Divergent ideation blends memory fragments into fresh possibilities, seeding future developmental arcs.'
      },
      {
        index: 7,
        stage: 'Integration',
        timeWindow: '14:00–16:00',
        primaryAspect: 'Narrative / Meaning‑Making',
        neuralCorrelates: 'Default mode–hippocampal loops, ventromedial prefrontal integration of episodic threads',
        description: 'Integration braids disparate experiences into coherent narrative form. Meaning-making aligns episodic memory with current identity commitments, consolidating lessons from prior stages.'
      },
      {
        index: 8,
        stage: 'Reflection',
        timeWindow: '16:00–18:00',
        primaryAspect: 'Meta‑awareness',
        neuralCorrelates: 'Default mode network activation, prefrontal–posterior cingulate coupling',
        description: 'During Reflection, attentional resources shift toward interoceptive monitoring and autobiographical processing. Meta-awareness increases the capacity to observe cognitive processes as they unfold — recognising meaning as both constructed and experienced. This stage represents a consolidation phase in the developmental cycle, not an endpoint.'
      },
      {
        index: 9,
        stage: 'Transcendence',
        timeWindow: '18:00–20:00',
        primaryAspect: 'Self‑Model / Identity',
        neuralCorrelates: 'Medial prefrontal decoupling with precuneus hubs and thalamocortical phase shifts',
        description: 'Transcendence loosens rigid self-representations so emergent patterns can surface. Identity becomes porous enough to host imaginal insight while remaining tethered to somatic safety.'
      },
      {
        index: 10,
        stage: 'Unity',
        timeWindow: '20:00–22:00',
        primaryAspect: 'Moral Reasoning',
        neuralCorrelates: 'Ventromedial prefrontal–limbic coherence, temporoparietal integration of ethical appraisal',
        description: 'Unity harmonises relational, ethical, and existential dimensions into a shared field. Moral imagination tracks the well-being of the collective, inviting choices that stabilise mutual flourishing.'
      },
      {
        index: 11,
        stage: 'Return',
        timeWindow: '22:00–24:00',
        primaryAspect: 'Mental Time Travel',
        neuralCorrelates: 'Hippocampal–cortical replay with theta–gamma coordination supporting consolidation',
        description: 'Return completes the cycle through reflective closure and future projection. Mental time travel revisits the journey, harvesting wisdom before cycling back to new beginnings.'
      }
    ];


    // Developmental profile generator (smooth rise → peak → taper)
    function makeDevProfile(i, stage, ring) {
      const len = DEV_STAGES;
      const arr = [];
      const phase = (stage-1) / 12;      // shift by nominal stage
      const amp = 0.6 + (ring/8)*0.3;    // outer rings slightly higher
      const noise = (seed)=> (Math.sin((i+1)*(seed+1.73))*0.04);
      for (let s=0; s<len; s++) {
        const t = s/(len-1);             // 0..1 lifespan
        const bell = Math.sin(Math.PI * (t*0.85 + phase*0.12));
        const base = Math.max(0, bell) * amp + 0.15*(1 - Math.pow(1-t, 3));
        const val = Math.max(0, Math.min(1, base + noise(s)));
        arr.push(Math.round(val*100));
      }
      return arr;
    }

    // Build a complete 32-aspect set for a given lens (mind/body/soul)
    function makeAspectSet(model) {
      return Array.from({ length: N_ASPECTS }, (_, i) => {
        const hue = Math.round((i * (360 / N_ASPECTS)) % 360);
        const stage = 1 + (i % 12);
        const ring  = 1 + (i % 8);
        const devProfile = makeDevProfile(i, stage, ring);
        const detail = FACULTY_DETAILS[i] || {};
        const base = {
          id: i+1,
          name: FACULTIES[i],
          stage, ring, hue,
          activation: devProfile[0],
          devProfile,
          definition: detail.definition || '',
          functionalRole: detail.functionalRole || '',
          symbolicResonance: detail.symbolicResonance || '',
          example: detail.example || '',
        };
        if (model === 'mind') {
          return Object.assign({}, base, {
            corePsychologicalRole: "Role placeholder",
            nsilSemanticSignature: "nsil:placeholder",
            semanticGravity: "attractor",
            quantumMode: ["particle","wave","field"][i%3],
            particleWaveFieldFunction: "propagation placeholder",
            brainRegion: "—",
            neurotransmitter: "—",
            energyMode: "—",
            matterOutput: "—",
          });
        }
        if (model === 'body') {
          return Object.assign({}, base, {
            brainRegion: BRAIN[i%8],
            neurotransmitter: ["5-HT","DA","NE","GABA","ACh","Oxytocin","Endorphins"][i%7],
            energyMode: MODES[i%MODES.length],
            matterOutput: "Physiological function",
          });
        }
        // soul
        return Object.assign({}, base, {
          archetypalSymbol: "Symbol",
          spiritualRole: "Role",
          nsilPrincipleSignature: "nsil:principle",
          brainRegion: "—",
          neurotransmitter: "—",
          energyMode: "—",
          matterOutput: "—",
        });
      });
    }

    // Three parallel datasets (placeholders until you provide canonical labels)
    const mindAspects = makeAspectSet('mind');
    const bodyAspects = makeAspectSet('body');
    const soulAspects = makeAspectSet('soul');

    // Active lens state
    let mode = 'mind';
    let aspects = mindAspects;
    window.aspects = aspects;
    window.dispatchEvent(new Event('selfClockAspectsUpdated'));

    /* ============================================================
       STATE + METRICS
    ============================================================ */
    const state = {
      resonanceThreshold: 18, // activation similarity to link nodes
      tutorial: false,
      tutorialIndex: 0,
      focusId: 1,
      devStage: 0,
    };

    // SCI: mean / (1 + stddev) * 100
    function computeSCI() {
      const vals = aspects.map(a => a.activation);
      const mean = vals.reduce((a,b)=>a+b,0) / vals.length;
      const variance = vals.reduce((acc, v)=> acc + Math.pow(v-mean, 2), 0) / vals.length;
      const std = Math.sqrt(variance);
      const sci = (mean / (1 + std)) * 100;
      return { mean, std, sci };
    }

    // Energy–Matter overview (simple but informative proxy)
    function computeEnergyMatter() {
      const total = aspects.reduce((s,a)=> s + a.activation, 0);
      const byNT = new Map();
      for (const a of aspects) {
        const k = a.neurotransmitter || '—';
        byNT.set(k, (byNT.get(k)||0) + a.activation);
      }
      const metabolic = total / (N_ASPECTS * 100);
      return { total, byNT, metabolic };
    }

    /* ============================================================
       NSIL FIELD VECTOR MAPPING
       ------------------------------------------------------------
       Adds semantic gravity metrics for each aspect.
       Each aspect gets eight harmonics normalized to 0..1.
    ============================================================ */

    function updateNSILFields() {
      aspects.forEach(a => {
        const normAct = a.activation / 100;
        const stageNorm = a.stage / 12;
        const ringNorm = a.ring / 8;

        a.nsil = {
          G: normAct * 0.9 + 0.1 * stageNorm,
          R: 0.6 + 0.4 * Math.sin(stageNorm * Math.PI),
          P: 0.5 + 0.5 * Math.cos(ringNorm * Math.PI / 2),
          A: normAct,
          N: 0.4 + 0.6 * (1 - Math.abs(0.5 - normAct)),
          T: 0.3 + 0.7 * (stageNorm * 0.9),
          Cx: 0.5 + 0.5 * Math.sin(ringNorm * Math.PI),
          Id: 0.7 + 0.3 * Math.cos(normAct * Math.PI / 2)
        };
      });
    }

    /* ============================================================
       DOM HELPERS
    ============================================================ */
    const el = sel => document.querySelector(sel);
    const listEl = el('#aspectList');
    const sciEl  = el('#sciVal');
    const emEl   = el('#emVal');
    const devSlider = el('#devStageSlider');
    const devVal = el('#devStageVal');
    const tutorialButton = document.getElementById('tutorialBtn');
    const tutorialModal = document.getElementById('tutorialModal');
    const tutorialModalOverlay = document.getElementById('tutorialModalOverlay');
    const closeTutorialModalBtn = document.getElementById('closeTutorialModal');
    const stageModalTitle = document.getElementById('stageModalTitle');
    const stageModalBody = document.getElementById('stageModalBody');

    let tutorialTriggerSource = null;
    const tutorialModal = el('#tutorialModal');
    const tutorialStageTitle = el('#tutorialStageTitle');
    const tutorialAspectFocus = el('#tutorialAspectFocus');
    const tutorialStageSummary = el('#tutorialStageSummary');
    const tutorialStageNarrative = el('#tutorialStageNarrative');
    const tutorialStageDynamic = el('#tutorialStageDynamic');

    function clampStageIndex(idx) {
      if (Number.isNaN(idx)) return 0;
      return Math.max(0, Math.min(STAGE_META.length - 1, idx));
    }

    function findStageAspect(meta) {
      if (!meta?.aspectKey) return null;
      return aspects.find(a => a.name === meta.aspectKey) || null;
    }

    function updateTutorialModal() {
      if (!tutorialModal) return;
      const stageIndex = clampStageIndex(state.devStage || 0);
      const meta = STAGE_META[stageIndex] || STAGE_META[0];
      const aspect = findStageAspect(meta);
      const focusLabel = meta.aspectFocus || aspect?.name || '—';

      if (tutorialStageTitle) {
        tutorialStageTitle.textContent = `Stage: ${meta.name} (${meta.window})`;
      }
      if (tutorialAspectFocus) {
        tutorialAspectFocus.textContent = `Aspect Focus: ${focusLabel}`;
      }
      if (tutorialStageSummary) {
        tutorialStageSummary.textContent = meta.summary(focusLabel);
      }
      if (tutorialStageNarrative) {
        tutorialStageNarrative.textContent = meta.resonance(focusLabel);
      }
      if (tutorialStageDynamic) {
        if (aspect) {
          tutorialStageDynamic.textContent = `Right now, ${aspect.name} is resonating at ${aspect.activation}/100 (Stage ${aspect.stage}, Ring ${aspect.ring}). Notice how it dialogues with attention, memory, emotion, and meaning as you move through the cycle.`;
        } else {
          tutorialStageDynamic.textContent = 'Notice how attention, memory, emotion, and meaning begin to overlap here — that resonance is what the Self-Clock is tracking.';
        }
      }
    }

    function showTutorialModal() {
      if (!tutorialModal) return;
      updateTutorialModal();
      tutorialModal.classList.add('is-visible');
      tutorialModal.setAttribute('aria-hidden', 'false');
      document.body.classList.add('modal-open');
      const closeBtn = tutorialModal.querySelector('.tutorial-modal__close');
      closeBtn?.focus();
    }

    function hideTutorialModal() {
      if (!tutorialModal) return;
      tutorialModal.classList.remove('is-visible');
      tutorialModal.setAttribute('aria-hidden', 'true');
      document.body.classList.remove('modal-open');
    }

    if (tutorialModal) {
      tutorialModal.addEventListener('click', (event) => {
        const target = event.target;
        if (!(target instanceof HTMLElement)) return;
        if (target.dataset.dismiss === 'tutorial' || target === tutorialModal) {
          hideTutorialModal();
        }
      });
    }

    function applyDevStage(stage){
      state.devStage = stage;
      if (devVal) devVal.textContent = stage + 1;
      aspects.forEach(a => { if (a.devProfile?.length === DEV_STAGES) a.activation = a.devProfile[stage]; });
      updateNSILFields();
      draw(); updateMetrics(); syncListRanges();
      announceStageChange(stage);
      if (tutorialModal?.classList.contains('active')) {
        updateStageModalContent();
      }
    }

    if (devSlider) devSlider.addEventListener('input', (e)=> applyDevStage(Number(e.target.value)));

    function getStageDetail(index) {
      return STAGE_DETAILS[index] || null;
    }

    function getActiveStageIndex() {
      return Math.max(0, Math.min(DEV_STAGES - 1, state.devStage));
    }

    function updateStageModalContent() {
      if (!stageModalBody) return;
      const activeIndex = getActiveStageIndex();
      const detail = getStageDetail(activeIndex) || getStageDetail(state.devStage);
      if (!detail) return;

      if (stageModalTitle) {
        stageModalTitle.textContent = `Stage: ${detail.stage} (${detail.timeWindow})`;
      }

      const aspect = aspects.find(a => a.name === detail.primaryAspect);
      const focusAspect = aspects.find(a => a.id === state.focusId);
      const focusStageIndex = focusAspect && Number.isFinite(focusAspect.stage)
        ? Math.max(0, Math.min(DEV_STAGES - 1, focusAspect.stage - 1))
        : null;
      const lines = [
        `<p><span class="stage-modal__highlight">Primary Aspect:</span> ${detail.primaryAspect}</p>`,
        `<p><span class="stage-modal__highlight">Neural Signature:</span> ${detail.neuralCorrelates}</p>`,
        `<p>${detail.description}</p>`
      ];

      if (aspect) {
        if (aspect.definition) {
          lines.push(`<p><strong>${aspect.name} focus:</strong> ${aspect.definition}</p>`);
        }
        if (aspect.functionalRole) {
          lines.push(`<p><strong>Functional role:</strong> ${aspect.functionalRole}</p>`);
        }
      }

      if (focusAspect && focusStageIndex !== null) {
        const focusDetail = getStageDetail(focusStageIndex);
        const focusStageName = focusDetail ? focusDetail.stage : `Stage ${focusStageIndex + 1}`;
        const focusWindow = focusDetail?.timeWindow ? ` (${focusDetail.timeWindow})` : '';
        if (focusStageIndex === activeIndex) {
          lines.push(`<p><strong>Focus context:</strong> ${focusAspect.name} resides in this stage (${focusStageName}${focusWindow}).</p>`);
        } else {
          lines.push(`<p><strong>Focus context:</strong> ${focusAspect.name} is mapped to Stage ${focusStageIndex + 1} · ${focusStageName}${focusWindow}, while the slider is tuned to Stage ${activeIndex + 1} · ${detail.stage}.</p>`);
        }
      }

      lines.push('<p class="stage-modal__footnote">Stage intelligence updates in real time as you explore the cycle.</p>');

      stageModalBody.innerHTML = lines.join('');
    }

    function openTutorialModal() {
      if (!tutorialModal) return;
      tutorialTriggerSource = document.activeElement instanceof HTMLElement ? document.activeElement : tutorialButton;
      updateStageModalContent();
      tutorialModal.classList.add('active');
      tutorialModal.setAttribute('aria-hidden', 'false');
      document.body.style.overflow = 'hidden';
      closeTutorialModalBtn?.focus();
    }

    function closeTutorialModal() {
      if (!tutorialModal) return;
      tutorialModal.classList.remove('active');
      tutorialModal.setAttribute('aria-hidden', 'true');
      document.body.style.overflow = '';
      if (tutorialTriggerSource && typeof tutorialTriggerSource.focus === 'function') {
        tutorialTriggerSource.focus();
      } else {
        tutorialButton?.focus();
      }
    }

    function announceStageChange(index) {
      const detail = getStageDetail(index);
      document.dispatchEvent(new CustomEvent('selfClockStageChanged', {
        detail: {
          index,
          stage: detail
        }
      }));
      if (tutorialModal?.classList.contains('active')) {
        updateStageModalContent();
      }
    }

    function syncStageFromFocus() {
      announceStageChange(getActiveStageIndex());
    }

    tutorialButton?.addEventListener('click', () => {
      openTutorialModal();
    });

    closeTutorialModalBtn?.addEventListener('click', () => closeTutorialModal());
    tutorialModalOverlay?.addEventListener('click', () => closeTutorialModal());

    window.addEventListener('selfClockAspectsUpdated', () => {
      if (tutorialModal?.classList.contains('active')) {
        updateStageModalContent();
      }
    });

    function tagHTML(a){
      if (mode==='mind') {
        return `<span class="tag">${a.quantumMode}</span><span class="tag">NSIL</span><span class="tag">${a.semanticGravity}</span>`;
      } else if (mode==='body') {
        return `<span class="tag">${a.brainRegion}</span><span class="tag">${String(a.neurotransmitter||'—').split(' ')[0]}</span><span class="tag">${a.energyMode}</span>`;
      }
      return `<span class="tag">${a.archetypalSymbol}</span><span class="tag">${a.spiritualRole}</span><span class="tag">NSIL</span>`;
    }

    function hsl(h, s=70, l=52) { return `hsl(${h} ${s}% ${l}%)`; }
    function hslAlpha(h, a=.25, s=70, l=50) { return `hsl(${h} ${s}% ${l}% / ${a})`; }

    function updateMetrics() {
      const { mean, std, sci } = computeSCI();
      const Cf = computeCf();
      const phiAligned = Math.abs(Cf - 1.618) < 0.05;
      const phiNote = phiAligned ? 'Φ-aligned' : `Δ ${(Cf - 1.618).toFixed(3)}`;

      sciEl.textContent =
        `${sci.toFixed(1)} (μ=${mean.toFixed(1)}, σ=${std.toFixed(1)}) · Cₓf=${Cf.toFixed(3)} ${phiNote}`;

      const { total, byNT, metabolic } = computeEnergyMatter();
      const top = [...byNT.entries()].sort((a,b)=>b[1]-a[1]).slice(0,2).map(([k,v])=> `${String(k).split(' ')[0]} ${Math.round(v)}` ).join(', ');
      emEl.textContent = `ΣE=${Math.round(total)} · NT↑ ${top || '—'} · Metabolic ${(metabolic*100).toFixed(0)}%`;

      document.querySelector('.vis').style.boxShadow = phiAligned
        ? '0 0 20px rgba(252,211,77,0.25)'
        : 'none';
    }

    function createAspectRow(a) {
      const item = document.createElement('div');
      item.className = 'aspect-item';
      item.role = 'option';
      item.tabIndex = 0;
      item.dataset.id = a.id;
      item.setAttribute('aria-selected', a.id === state.focusId ? 'true' : 'false');

      const r1 = document.createElement('div');
      r1.className = 'row';
      r1.innerHTML = `<div class="name"><span class="dot" style="background:${hsl(a.hue)}"></span>${a.name}</div>
                      <div class="tag">Stage ${a.stage} · Ring ${a.ring}</div>`;

      const r2 = document.createElement('div');
      r2.className = 'row';
      const label = document.createElement('label');
      label.textContent = `Activation: ${a.activation}`;
      label.style.flex = '1';
      label.htmlFor = `rng-${a.id}`;

      const range = document.createElement('input');
      range.type = 'range';
      range.min = 0; range.max = 100; range.value = a.activation; range.id = `rng-${a.id}`;
      range.setAttribute('aria-label', `${a.name} activation`);
      range.addEventListener('input', (e) => {
        a.activation = Number(e.target.value);
        updateNSILFields();
        label.textContent = `Activation: ${a.activation}`;
        draw();
        updateMetrics();
      });

      const detailsBtn = document.createElement('button');
      detailsBtn.className = 'btn secondary';
      detailsBtn.textContent = 'Details';
      detailsBtn.addEventListener('click', () => openModal(a));

      r2.append(label, range, detailsBtn);

      const r3 = document.createElement('div');
      r3.className = 'tags';
      r3.innerHTML = `${tagHTML(a)}`;

      item.append(r1, r2, r3);

      item.addEventListener('click', () => { state.focusId = a.id; refreshListSelection(); draw(); syncStageFromFocus(); });
      item.addEventListener('keydown', (ev) => {
        if (ev.key === 'Enter' || ev.key === ' ') { ev.preventDefault(); openModal(a); }
      });

      return item;
    }

    function refreshListSelection() {
      [...listEl.children].forEach(ch => ch.setAttribute('aria-selected', ch.dataset.id == state.focusId ? 'true':'false'));
    }

    function buildList() {
      listEl.innerHTML = '';
      aspects.forEach(a => listEl.appendChild(createAspectRow(a)));
    }

    /* ============================================================
       MODAL (tooltip-style info + slider)
    ============================================================ */
    const dlg = el('#infoModal');
    const mTitle = el('#mTitle');
    const mDef = el('#mDef');
    const mFunctional = el('#mFunctional');
    const mSymbolic = el('#mSymbolic');
    const mExample = el('#mExample');
    const mBrain = el('#mBrain');
    const mNT = el('#mNT');
    const mEnergy = el('#mEnergy');
    const mStage = el('#mStage');
    const mSlider = el('#mSlider');
    const mActVal = el('#mActVal');
    const mSummary = el('#mSummary');

    let currentAspect = null;

    function openModal(a) {
      currentAspect = a;
      mTitle.textContent = a.name;
      mDef.textContent = a.definition;
      mFunctional.textContent = a.functionalRole || '—';
      mSymbolic.textContent = a.symbolicResonance || '—';
      mExample.textContent = a.example || '—';
      if (mode==='mind') {
        mBrain.textContent = a.nsilSemanticSignature || '—';
        mNT.textContent = `${a.quantumMode || '—'} · ${a.particleWaveFieldFunction || ''}`;
        mEnergy.textContent = `${a.semanticGravity || '—'}`;
        mStage.textContent = `Stage ${a.stage} · Ring ${a.ring}`;
      } else if (mode==='body') {
        mBrain.textContent = a.brainRegion;
        mNT.textContent = a.neurotransmitter;
        mEnergy.textContent = a.energyMode;
        mStage.textContent = `Stage ${a.stage} · Ring ${a.ring}`;
      } else {
        mBrain.textContent = a.archetypalSymbol || '—';
        mNT.textContent = a.spiritualRole || '—';
        mEnergy.textContent = a.nsilPrincipleSignature || '—';
        mStage.textContent = `Stage ${a.stage} · Ring ${a.ring}`;
      }
      mSlider.value = String(a.activation);
      mActVal.textContent = String(a.activation);
      updateModalSummary();
      dlg.showModal();
    }

    function updateModalSummary() {
      if (!currentAspect) return;
      const energyIn = currentAspect.activation;
      const region = currentAspect.brainRegion || '—';
      const ntStr = String(currentAspect.neurotransmitter || '—');
      const neuroOut = ntStr.split(' ')[0];
      const metabolic = Math.round((energyIn/100) * 100);
      mSummary.textContent = `Energy in: ${energyIn} → ${region} → NT: ${neuroOut} → functional output: ${currentAspect.matterOutput || '—'} (metabolic load ≈ ${metabolic}%)`;
    }

    dlg.addEventListener('close', ()=>{ currentAspect = null; });
    dlg.addEventListener('click', (e)=>{
      const rect = dlg.getBoundingClientRect();
      if (e.clientY < rect.top || e.clientY > rect.bottom || e.clientX < rect.left || e.clientX > rect.right) dlg.close();
    });
    dlg.querySelector('button[value="cancel"]').addEventListener('click', ()=> dlg.close());
    mSlider.addEventListener('input', (e) => {
      if (!currentAspect) return;
      currentAspect.activation = Number(e.target.value);
      mActVal.textContent = String(currentAspect.activation);
      updateNSILFields();
      updateModalSummary();
      const row = listEl.querySelector(`[data-id="${currentAspect.id}"]`);
      if (row) {
        const label = row.querySelector('label');
        const range = row.querySelector('input[type="range"]');
        if (range) range.value = String(currentAspect.activation);
        if (label) label.textContent = `Activation: ${currentAspect.activation}`;
      }
      draw();
      updateMetrics();
    });

    /* ============================================================
       CANVAS RENDERING
    ============================================================ */
    const canvas = el('#clockCanvas');
    const ctx = canvas.getContext('2d');

    function resizeCanvas() {
      const dpr = Math.max(1, window.devicePixelRatio || 1);
      const { clientWidth:w, clientHeight:h } = canvas;
      canvas.width = Math.floor(w * dpr);
      canvas.height = Math.floor(h * dpr);
      ctx.setTransform(dpr, 0, 0, dpr, 0, 0);
      center.x = w/2; center.y = h/2;
      draw();
    }
    window.addEventListener('resize', resizeCanvas);

    function polar(angle, radius) {
      return { x: center.x + Math.cos(angle)*radius, y: center.y + Math.sin(angle)*radius };
    }

    function drawRings(maxR) {
      const rings = 8;
      const step = maxR / rings;
      ctx.save();
      for (let i=1;i<=rings;i++) {
        ctx.beginPath();
        ctx.strokeStyle = i % 2 ? '#1a214a' : '#161c3f';
        ctx.lineWidth = 1;
        ctx.arc(center.x, center.y, step*i, 0, TWO_PI);
        ctx.stroke();
      }
      ctx.restore();
    }

    function drawStageLines(maxR) {
      const count = 12;
      ctx.save();
      ctx.strokeStyle = '#24306f';
      ctx.lineWidth = 1;
      for (let s=0; s<count; s++) {
        const angle = (s/count)*TWO_PI - Math.PI/2;
        const p1 = polar(angle, 10);
        const p2 = polar(angle, maxR);
        ctx.beginPath();
        ctx.moveTo(p1.x, p1.y);
        ctx.lineTo(p2.x, p2.y);
        ctx.stroke();
      }
      ctx.restore();
    }

    function drawNodes(maxR) {
      const nodeR = 10;
      const radius = maxR * 0.92;
      const out = [];
      aspects.forEach((a, i) => {
        const angle = (i/N_ASPECTS)*TWO_PI - Math.PI/2;
        const p = polar(angle, radius);
        const arcSize = Math.max(0.05, a.activation/100) * (TWO_PI / N_ASPECTS);
        ctx.beginPath();
        ctx.arc(center.x, center.y, radius, angle - arcSize/2, angle + arcSize/2);
        const sat = 40 + (a.nsil?.G || 0) * 60;
        const light = 30 + (a.nsil?.A || 0) * 40;
        ctx.strokeStyle = hsl(a.hue, sat, light);
        ctx.lineWidth = 8;
        ctx.globalAlpha = 0.55;
        ctx.stroke();
        ctx.globalAlpha = 1;

        ctx.beginPath();
        ctx.fillStyle = hsl(a.hue, sat, light);
        ctx.arc(p.x, p.y, nodeR, 0, TWO_PI);
        ctx.fill();
        ctx.lineWidth = (a.id === state.focusId) ? 3 : 1.5;
        ctx.strokeStyle = (a.id === state.focusId) ? '#fde68a' : '#0b0f2a';
        ctx.stroke();

        ctx.fillStyle = '#cbd5f1';
        ctx.font = '12px ui-sans-serif, system-ui, -apple-system, Segoe UI';
        ctx.textAlign = 'center';
        ctx.fillText(a.name, p.x, p.y - (nodeR+8));

        out.push({ id: a.id, x: p.x, y: p.y, angle });
      });
      return out;
    }

    function drawResonanceLinks(nodePoints) {
      ctx.save();
      for (let i=0;i<aspects.length;i++) {
        for (let j=i+1;j<aspects.length;j++) {
          const ai = aspects[i], aj = aspects[j];
          const sim = Math.abs(ai.activation - aj.activation);
          const sameStage = (ai.stage === aj.stage);
          const sameRing = (ai.ring === aj.ring);
          const shouldLink = sim <= state.resonanceThreshold || sameStage || sameRing;
          if (!shouldLink) continue;
          const pi = nodePoints[i], pj = nodePoints[j];
          const d = Math.hypot(pi.x - pj.x, pi.y - pj.y);
          const alpha = Math.min(0.35, 0.08 + (1 - sim/100) * 0.25) * (sameStage ? 1.25 : 1) * (sameRing ? 1.15 : 1);
          ctx.beginPath();
          const grad = ctx.createLinearGradient(pi.x, pi.y, pj.x, pj.y);
          grad.addColorStop(0, 'rgba(52, 211, 153, '+alpha.toFixed(3)+')');
          grad.addColorStop(1, 'rgba(125, 211, 252, '+alpha.toFixed(3)+')');
          ctx.strokeStyle = grad;
          ctx.lineWidth = Math.max(0.5, 2.5 - (d/260));
          ctx.moveTo(pi.x, pi.y);
          ctx.lineTo(pj.x, pj.y);
          ctx.stroke();
        }
      }
      ctx.restore();
    }

    function drawTutorialHalo(nodePoints) {
      if (!state.tutorial) return;
      const idx = (state.tutorialIndex % aspects.length);
      const { x, y } = nodePoints[idx];
      const t = performance.now()/1000;
      const pulse = 10 + 6*Math.sin(t*2);
      ctx.save();
      const g = ctx.createRadialGradient(x, y, 2, x, y, 42+pulse);
      g.addColorStop(0, 'rgba(245, 158, 11, 0.7)');
      g.addColorStop(1, 'rgba(245, 158, 11, 0.0)');
      ctx.fillStyle = g;
      ctx.beginPath();
      ctx.arc(x, y, 42+pulse, 0, TWO_PI);
      ctx.fill();
      ctx.restore();
    }

    function draw() {
      const { width:w, height:h } = canvas;
      ctx.clearRect(0,0,w,h);
      const maxR = Math.min(w, h)/2 - 30;
      drawRings(maxR);
      drawStageLines(maxR);
      const points = drawNodes(maxR);
      drawResonanceLinks(points);
      drawTutorialHalo(points);
    }

    // Animation loop for tutorial halo
    function tick() { if (state.tutorial) draw(); requestAnimationFrame(tick); }

    /* ============================================================
       HIT TEST & INTERACTION (mouse/touch)
    ============================================================ */
    function getMousePos(evt) {
      const rect = canvas.getBoundingClientRect();
      return { x: evt.clientX - rect.left, y: evt.clientY - rect.top };
    }

    function nodeAt(x, y) {
      const { width:w, height:h } = canvas;
      const maxR = Math.min(w, h)/2 - 30; const radius = maxR * 0.92; const nodeR = 12;
      for (let i=0;i<aspects.length;i++) {
        const angle = (i/N_ASPECTS)*TWO_PI - Math.PI/2;
        const p = polar(angle, radius);
        if (Math.hypot(x - p.x, y - p.y) <= nodeR+2) return aspects[i];
      }
      return null;
    }

    canvas.addEventListener('click', (e)=>{
      const p = getMousePos(e);
      const a = nodeAt(p.x, p.y);
      if (a) { state.focusId = a.id; refreshListSelection(); draw(); syncStageFromFocus(); openModal(a); }
    });

    // Basic keyboard navigation
    window.addEventListener('keydown', (e)=>{
      if (tutorialModal?.classList.contains('active')) {
        if (e.key === 'Escape') {
          e.preventDefault();
          closeTutorialModal();
        }
        return;
      }

      const key = e.key.toLowerCase();
      if (key === 'escape') {
        if (tutorialModal?.classList.contains('is-visible')) { hideTutorialModal(); return; }
        if (dlg?.open) { dlg.close(); return; }
      }
      if (key === 't') { toggleTutorial(); }
      if (key === 'r') { randomize(); }
      if (key === 'e') { exportJSON(); }
      if (key === '0') { deactivateAll(); }
      if (key === 'arrowright' || key === 'arrowdown') { e.preventDefault(); moveFocus(1); }
      if (key === 'arrowleft' || key === 'arrowup') { e.preventDefault(); moveFocus(-1); }
      if (key === 'enter') { e.preventDefault(); const a = aspects.find(x=>x.id===state.focusId); if (a) openModal(a); }
    });

    function moveFocus(delta) {
      const idx = aspects.findIndex(a => a.id === state.focusId);
      const next = (idx + delta + aspects.length) % aspects.length;
      state.focusId = aspects[next].id;
      refreshListSelection();
      draw();
      const row = listEl.querySelector(`[data-id="${state.focusId}"]`);
      row?.scrollIntoView({ behavior: 'smooth', block: 'nearest' });
      syncStageFromFocus();
    }

    /* ============================================================
       COMMANDS & EXPORT
    ============================================================ */
    function randomize() {
      aspects.forEach(a => a.activation = Math.round(Math.random()*100));
      updateNSILFields();
      syncListRanges(); draw(); updateMetrics();
    }

    function deactivateAll() {
      aspects.forEach(a => a.activation = 0);
      updateNSILFields();
      syncListRanges(); draw(); updateMetrics();
    }

    function syncListRanges() {
      aspects.forEach(a => {
        const row = listEl.querySelector(`[data-id="${a.id}"]`);
        if (!row) return;
        const range = row.querySelector('input[type="range"]');
        const label = row.querySelector('label');
        if (range) range.value = a.activation;
        if (label) label.textContent = `Activation: ${a.activation}`;
      });
    }

    // Build payload separately so we can unit-test it
    function buildExportPayload() {
      const { mean, std, sci } = computeSCI();
      const { total, byNT, metabolic } = computeEnergyMatter();
      const Cf = computeCf();
      const phiAlignment = Math.abs(Cf - PHI) < 0.05;
      return {
        generatedAt: new Date().toISOString(),
        model: `32 Aspect Developmental Self Clock — ${mode}`,
        devStage: state.devStage,
        metrics: { mean, std, sci, Cf, phiAlignment },
        energyMatter: { total, byNT: Object.fromEntries(byNT), metabolic },
        aspects: aspects.map(a => ({
          ...a,
          nsil: a.nsil
        }))
      };
    }

    function exportJSON() {
      const payload = buildExportPayload();
      const blob = new Blob([JSON.stringify(payload, null, 2)], { type: 'application/json' });
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url; a.download = 'self-clock-export.json';
      document.body.appendChild(a); a.click(); a.remove();
      URL.revokeObjectURL(url);
    }

    /* ============================================================
       TUTORIAL / WALKTHROUGH MODE
    ============================================================ */
    let tutorialTimer = null;
    function toggleTutorial() {
      state.tutorial = !state.tutorial;
      const tutorialModeBtn = document.getElementById('btnTutorialMode');
      tutorialModeBtn?.setAttribute('aria-pressed', String(state.tutorial));
      if (tutorialModeBtn) {
        tutorialModeBtn.textContent = state.tutorial ? '⏸ Tutorial Mode' : '▶ Tutorial Mode';
      }
      const tutorialBtn = document.getElementById('btnTutorial');
      tutorialBtn?.setAttribute('aria-pressed', String(state.tutorial));
      if (tutorialBtn) tutorialBtn.textContent = state.tutorial ? '⏸ Tutorial' : '▶ Tutorial';
      if (state.tutorial) {
        showTutorialModal();
        if (!tutorialTimer) tutorialTimer = setInterval(()=>{
          state.tutorialIndex = (state.tutorialIndex + 1) % aspects.length;
          state.focusId = aspects[state.tutorialIndex].id;
          refreshListSelection(); draw(); syncStageFromFocus();
        }, 1400);
        syncStageFromFocus();
      } else {
        hideTutorialModal();
        clearInterval(tutorialTimer); tutorialTimer = null; draw();
        syncStageFromFocus();
      }
    }

    /* ============================================================
       UI WIRING
    ============================================================ */
    document.getElementById('btnTutorialMode').addEventListener('click', toggleTutorial);
    document.getElementById('btnRandomize').addEventListener('click', randomize);
    document.getElementById('btnDeactivate').addEventListener('click', deactivateAll);
    document.getElementById('btnExport').addEventListener('click', exportJSON);

    function setMode(newMode){
      mode = newMode;
      aspects = (mode==='mind') ? mindAspects : (mode==='body') ? bodyAspects : soulAspects;
      window.aspects = aspects;
      window.dispatchEvent(new Event('selfClockAspectsUpdated'));
      updateNSILFields();
      document.getElementById('modeMind').classList.toggle('secondary', mode!=='mind');
      document.getElementById('modeBody').classList.toggle('secondary', mode!=='body');
      document.getElementById('modeSoul').classList.toggle('secondary', mode!=='soul');
      document.getElementById('modeMind').setAttribute('aria-pressed', String(mode==='mind'));
      document.getElementById('modeBody').setAttribute('aria-pressed', String(mode==='body'));
      document.getElementById('modeSoul').setAttribute('aria-pressed', String(mode==='soul'));
      buildList();
      applyDevStage(state.devStage);
      updateMetrics();
      draw();
      if (tutorialModal?.classList.contains('is-visible')) {
        updateTutorialModal();
      }
    }

    document.getElementById('modeMind').addEventListener('click', ()=> setMode('mind'));
    document.getElementById('modeBody').addEventListener('click', ()=> setMode('body'));
    document.getElementById('modeSoul').addEventListener('click', ()=> setMode('soul'));

    /* ============================================================
       SELF-TESTS (basic runtime checks) — shown in console
       We add tests since none existed previously.
    ============================================================ */
    function runSelfTests() {
      const results = [];
      function assert(name, cond) { results.push({ name, pass: !!cond }); }

      // Test 1: DEV_STAGES
      assert('DEV_STAGES == 12', DEV_STAGES === 12);

      // Test 2: Each dataset has 32 aspects
      assert('mindAspects length', mindAspects.length === 32);
      assert('bodyAspects length', bodyAspects.length === 32);
      assert('soulAspects length', soulAspects.length === 32);

      // Test 3: devProfile lengths
      assert('mind devProfile[0].length == 12', mindAspects[0].devProfile.length === 12);

      // Test 4: SCI on uniform activations → std≈0, sci≈mean*100
      const bak = aspects;
      aspects = [{ activation: 50 },{ activation: 50 },{ activation: 50 },{ activation: 50 }];
      const { mean, std, sci } = computeSCI();
      assert('SCI std == 0', Math.abs(std - 0) < 1e-9);
      assert('SCI value', Math.abs(sci - (50/(1+0)*100)) < 1e-6);
      aspects = bak;

      // Test 5: export payload shape
      const payload = buildExportPayload();
      assert('payload.aspects length == 32', Array.isArray(payload.aspects) && payload.aspects.length === 32);
      assert('payload.metrics has sci', typeof payload.metrics.sci === 'number');

      // Report
      const passCount = results.filter(r=>r.pass).length;
      const fail = results.filter(r=>!r.pass);
      console.log('%cSelf-tests:', 'font-weight:bold');
      results.forEach(r=> console.log(r.pass ? '✅' : '❌', r.name));
      if (fail.length) {
        console.warn('Some self-tests failed:', fail);
      } else {
        console.log(`All ${passCount} self-tests passed.`);
      }
    }

    // Initial build & draw
    buildList();
    updateNSILFields();
    updateMetrics();
    resizeCanvas();
    applyDevStage(state.devStage);
    requestAnimationFrame(tick);

    // Footer year
    document.getElementById('year').textContent = new Date().getFullYear();

    /* ============================================================
       SCIENCE NOTES (for researchers inside code comments)
       ----------------------------------------------------
       • SCI implements the user's formula: mean/(1+stddev)*100.
       • We visualize C = E × MC (concept → energy × matter × cognition) via
         the info modal's pipeline description and resonance links.
       • 12 radial cross-lines = expanded Erikson-like developmental stages; 
         use your mapping to stage names in your dataset if available.
       • 8 concentric rings = anatomy/energy zones; link to somatic/energetic
         layers (e.g., brainstem → cortex, fascia layers, chakric analogues).
       • Resonance edges connect nodes with similar activation OR sharing
         stage/ring, encoding feedback/overlap and nonlinearity.
       • Tutorial traces a simple loop through aspects. For research demos,
         extend by adding causal/feedback animations (mind→body→action→mind).
       • Accessibility: All controls are reachable by keyboard; modal is a
         native <dialog>; listbox items are focusable and announce changes.
    ============================================================ */

    /* ============================================================
       LAYER-1 Φ CONTINUUM EXTENSION
       ------------------------------------------------------------
       Adds φ alignment, Cf metric, and harmonic visualization overlay
       using the same activation data from aspects[].
    ============================================================ */

    const PHI = 1.618;
    const phiOverlay = document.createElement('canvas');
    phiOverlay.id = 'phiOverlay';
    phiOverlay.style.position = 'absolute';
    phiOverlay.style.top = '0';
    phiOverlay.style.left = '0';
    phiOverlay.style.width = '100%';
    phiOverlay.style.height = '100%';
    phiOverlay.style.pointerEvents = 'none';
    document.querySelector('.vis').appendChild(phiOverlay);
    const phiCtx = phiOverlay.getContext('2d');

    function resizePhi() {
      const dpr = Math.max(1, window.devicePixelRatio||1);
      phiOverlay.width = phiOverlay.clientWidth * dpr;
      phiOverlay.height = phiOverlay.clientHeight * dpr;
      phiCtx.setTransform(dpr,0,0,dpr,0,0);
    }
    window.addEventListener('resize', resizePhi);
    resizePhi();

    function computeCf() {
      const vals = aspects.map(a=>a.activation);
      const mean = vals.reduce((a,b)=>a+b,0)/vals.length;
      const variance = vals.reduce((s,v)=>s+Math.pow(v-mean,2),0)/vals.length;
      const std = Math.sqrt(variance);
      const CI = mean/100;
      const RL = 1 - std/100;
      const EER = Math.abs(1 - CI);
      return (CI*RL)/Math.max(EER,0.001);
    }

    function drawPhiOverlay(t=0) {
      const {width:w,height:h}=phiOverlay;
      phiCtx.clearRect(0,0,w,h);
      const Cf = computeCf();
      const phiAligned = Math.abs(Cf - PHI) < 0.05;
      const radius = Math.min(w,h)/3;
      const cx=w/2, cy=h/2;
      const grad = phiCtx.createRadialGradient(cx,cy,0,cx,cy,radius*1.2);
      grad.addColorStop(0, phiAligned ? 'rgba(252,211,77,0.15)' : 'rgba(124,58,237,0.05)');
      grad.addColorStop(1, 'rgba(0,0,0,0)');
      phiCtx.fillStyle = grad;
      phiCtx.beginPath();
      phiCtx.arc(cx,cy,radius,0,Math.PI*2);
      phiCtx.fill();
      const txt = phiAligned ? 'φ-aligned' : `Δ ${(Cf-PHI).toFixed(3)}`;
      phiCtx.font='16px system-ui';
      phiCtx.textAlign='center';
      phiCtx.fillStyle=phiAligned?'#fde68a':'#94a3b8';
      phiCtx.fillText(`Cₓf ${Cf.toFixed(3)} → ${txt}`,cx,cy+radius+24);
      requestAnimationFrame(drawPhiOverlay);
    }
    requestAnimationFrame(drawPhiOverlay);
    runSelfTests();
  </script>
</body>
</html>
